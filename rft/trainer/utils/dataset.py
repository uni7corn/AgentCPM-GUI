"""Example Datasets for ARL.
Each dataset item must return following key in a dict:

- `id`: A unique index for the data entry.
- `prompt`: Chat Hisotry as model inputs, must be list of dict.

If you want to conduct multi-turn ARL, you should also provide `next_id` that indicate the next step inputs in the dataset.


"""


import os
import json
import re
import io
import random
from tqdm import tqdm
from torch.utils.data import Dataset
from PIL import Image
from typing import Optional
import zmq

def load_resized_image(img_file:str|io.BytesIO, max_line_res: Optional[int] = None):
    origin_img = Image.open(img_file).convert("RGB")
    w,h = origin_img.size
    if max_line_res is not None:
        if h > max_line_res:
            w = int(w * max_line_res / h)
            h = max_line_res
        if w > max_line_res:
            h = int(h * max_line_res / w)
            w = max_line_res
        img = origin_img.resize((w,h),resample=Image.Resampling.LANCZOS)
    else:
        img = origin_img
        
    return img,origin_img

class GUIRFTDataset(Dataset):
    def __init__(self, jsonl_file_path: str, max_line_res: int|None = None, *args, **kwargs):
        super().__init__()
        self.data = []
        self.jsonl_file_path = jsonl_file_path
        with open(jsonl_file_path, "r") as f:
            for line in tqdm(f.readlines(), desc="Loading dataset",dynamic_ncols=True):
                try:
                    self.data.append(json.loads(line))
                except:
                    print("Error while loading line.")
                    continue
        self.image_root = os.path.dirname(os.path.dirname(jsonl_file_path))
        self.max_line_res = max_line_res


    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, index):
        item = self.data[index]
        
        try:
            # process the conversation
            user_query = item["conversations"][-2]["content"]
            user_query = re.match(r"<Question>(.*?)</Question>", user_query,re.DOTALL).group(1)
            action = json.loads(item["conversations"][-1]['content'])
        except:
            print("Error while processing conversation.")
            return self[index - 53]
        
        for img_id,img_file in item["image"].items():
            try:
                if os.path.exists(img_file):
                    origin_img = Image.open(img_file).convert("RGB")
                else:
                    origin_img = Image.open(os.path.join(self.image_root,img_file)).convert("RGB")
            except:
                print("Error while loading image: ", img_file)
                return self[index - 53]
            w,h = origin_img.size
            # resize the max height and width to 1000
            if self.max_line_res is not None:
                max_line = self.max_line_res
                if h > max_line:
                    w = int(w * max_line / h)
                    h = max_line
                if w > max_line:
                    h = int(h * max_line / w)
                    w = max_line
            img = origin_img.resize((w,h),resample=Image.Resampling.LANCZOS)
            
            resolution = (origin_img.size, img.size)
            break
        
        conv = []
        
        def get_random_coordinate():
            return [random.randint(0,1000),random.randint(0,1000)]
        
        conv.append({"role":"system","content":SFT_PROMPT})
        conv.append({"role": "user", "content": [
            f"<Question>{user_query}</Question>\nå½“å‰å±å¹•æˆªå›¾ï¼š",
            img, 
        ]})
        if item.get("bbox",None) is None or len(item.get("bbox",None)) == 0:
            bbox = None
        else:
            bbox = item["bbox"]
        if item.get("bbox2",None) is None or len(item.get("bbox2",None)) == 0:
            bbox2 = None
        else:
            bbox2 = item["bbox2"]
        return {
            "id": index,
            "step_id": 0,
            "resolution": resolution,
            "bboxs": [bbox,bbox2],
            "solution": action,
            "prompt": conv
        }


class GUIMTRFTDataset(GUIRFTDataset):
    """Multiturn RFT Dataset"""
    def __init__(
        self, 
        global_task_dispatch_addr: str,
        jsonl_file_path: str, 
        hist_length: int = 3,
        max_line_res: int|None = None, 
        *args, **kwargs
    ):
        super().__init__(
            jsonl_file_path=jsonl_file_path,
            max_line_res=max_line_res,
            *args, **kwargs
        )
        self.hist_length = hist_length
        self.global_task_dispatch_addr = global_task_dispatch_addr
        self.zmqctx = None
        
        
    def lazy_init(self):
        if self.zmqctx is None:
            self.zmqctx = zmq.Context()
            self.step_response_receiver = self.zmqctx.socket(zmq.REQ)
            self.step_response_receiver.connect(self.global_task_dispatch_addr)
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, index):
        self.lazy_init()
        
        real_index = index % len(self.data)
        step_index = index // len(self.data)
        item = self.data[real_index]
        
        # in multi-turn training, we set next_id to indicate next step position
        next_id = index + len(self.data) if 4+2*step_index < len(item["conversations"]) else None
        
        try:
            user_query = item["conversations"][1+2*step_index]["content"]
            user_query = re.match(r"<Question>(.*?)</Question>", user_query,re.DOTALL).group(1)
            action = json.loads(item["conversations"][2+2*step_index]["content"])
        except Exception as e:
            print("Error while processing conversation: ", e, item["conversations"])
            action = item["conversations"][-1]["content"]
            return {
                "id": index,
                "resolution": None,
                "bboxs": [None,None],
                "solution": action,
                "prompt": item["conversations"][:-1],
                "step_id": 0,
                "next_id": None
            }
        
        # conv = [{"role":"system","content":SFT_PROMPT}]
        # conv = [{"role":"system","content":random.choice(SYSTEM_PROMPTS)}]
        conv = [{"role":"system","content":THINK_PROMPT}]
        # Append history
        for step_id in range(step_index + 1):
            if step_id > step_index - self.hist_length:
                if step_id != step_index:
                    line_res = 448
                else:
                    line_res = self.max_line_res
                img,ori_img = load_resized_image(item["image"][f"<image_{step_id:02}>"],max_line_res=line_res)
                conv.append({"role":"user","content":[
                    "å½“å‰å±å¹•æˆªå›¾ï¼š",
                    img
                ]})
            else:
                conv.append({"role":"user","content":"// å†å²å›¾åƒï¼Œæ— æ³•æ˜¾ç¤º"})
                
            if step_index > 0 and step_id != step_index:
                # gather model's history completions
                self.step_response_receiver.send_pyobj({
                    "get": real_index + len(self.data) * step_id,
                    "pop": True if next_id is None else False
                })
                res = self.step_response_receiver.recv_string()
                conv.append({"role":"assistant","content":res})

            
        # add user query
        if isinstance(conv[-1]["content"],list):
            conv[-1]["content"][0] = f"<Question>{user_query}</Question>\n" + conv[-1]["content"][0]
        else:
            conv[-1]["content"] = f"<Question>{user_query}</Question>\n" + conv[-1]["content"]
        
        resolution = (ori_img.size,img.size)
        
        try:
            bbox1 = item["bbox"][step_id]
        except:
            bbox1 = None
            
        
        return {
            "id": index,
            "resolution": resolution,
            "bboxs": [bbox1,None],
            "solution": action,
            "prompt": conv,
            "step_id": step_index,
            "next_id": next_id
        }



def compact_json_dumps(obj):
    return json.dumps(obj, indent=None, separators=(",", ":"), ensure_ascii=False)


SCHEMA = {
    "type": "object",
    "description": "æ‰§è¡Œæ“ä½œå¹¶å†³å®šå½“å‰ä»»åŠ¡çŠ¶æ€",
    "additionalProperties": False,
    # "required": ["thought"],
    "optional": ["thought"],
    "properties": {
        "thought": {
          "type": "string",
          "description": "æ™ºèƒ½ä½“çš„æ€ç»´è¿‡ç¨‹"
        },
        "POINT": {
        "$ref": "#/$defs/Location",
        "description": "ç‚¹å‡»å±å¹•ä¸Šçš„æŒ‡å®šä½ç½®"
        },
        "to": {
        "description": "ç§»åŠ¨ï¼Œç»„åˆæ‰‹åŠ¿å‚æ•°",
        "oneOf": [
            {
            "enum": [
                "up",
                "down",
                "left",
                "right"
            ],
            "description": "ä»å½“å‰ç‚¹ï¼ˆPOINTï¼‰å‡ºå‘ï¼Œæ‰§è¡Œæ»‘åŠ¨æ‰‹åŠ¿æ“ä½œï¼Œæ–¹å‘åŒ…æ‹¬å‘ä¸Šã€å‘ä¸‹ã€å‘å·¦ã€å‘å³"
            },
            {
            "$ref": "#/$defs/Location",
            "description": "ç§»åŠ¨åˆ°æŸä¸ªä½ç½®"
            }
        ]
        },
        "duration": {
        "type": "integer",
        "description": "åŠ¨ä½œæ‰§è¡Œçš„æ—¶é—´æˆ–ç­‰å¾…æ—¶é—´ï¼Œæ¯«ç§’",
        "minimum": 0,
        "default": 200
        },
        "PRESS": {
        "type": "string",
        "description": "è§¦å‘ç‰¹æ®ŠæŒ‰é”®ï¼ŒHOMEä¸ºå›åˆ°ä¸»é¡µæŒ‰é’®ï¼ŒBACKä¸ºè¿”å›æŒ‰é’®ï¼ŒENTERä¸ºå›è½¦æŒ‰é’®",
        "enum": [
            "HOME",
            "BACK",
            "ENTER"
        ]
        },
        "TYPE": {
        "type": "string",
        "description": "è¾“å…¥æ–‡æœ¬"
        },
        "STATUS": {
        "type": "string",
        "description": "å½“å‰ä»»åŠ¡çš„çŠ¶æ€ã€‚ç‰¹æ®Šæƒ…å†µï¼šsatisfiedï¼Œæ— éœ€æ“ä½œï¼›impossibleï¼Œä»»åŠ¡æ— æ³•å®Œæˆï¼›interruptï¼Œä»»åŠ¡ä¸­æ–­ï¼›need_feedbackï¼Œéœ€è¦ç”¨æˆ·åé¦ˆï¼›",
        "enum": [
            "continue",
            "finish",
            "satisfied",
            "impossible",
            "interrupt",
            "need_feedback"
        ],
        "default": "continue"
        }
    },
    "$defs": {
        "Location": {
        "type": "array",
        "description": "åæ ‡ä¸ºç›¸å¯¹äºå±å¹•å·¦ä¸Šè§’ä½åŸç‚¹çš„ç›¸å¯¹ä½ç½®ï¼Œå¹¶ä¸”æŒ‰ç…§å®½é«˜æ¯”ä¾‹ç¼©æ”¾åˆ°0ï½1000ï¼Œæ•°ç»„ç¬¬ä¸€ä¸ªå…ƒç´ ä¸ºæ¨ªåæ ‡xï¼Œç¬¬äºŒä¸ªå…ƒç´ ä¸ºçºµåæ ‡y",
        "items": {
            "type": "integer",
            "minimum": 0,
            "maximum": 1000
        },
        "minItems": 2,
        "maxItems": 2
        }
    }
}

THINK_PROMPT = """# Role
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹

# è¾“å‡ºæ ¼å¼
ä½ æœ‰å¤šç§å¯é€‰çš„è¾“å‡ºæ ¼å¼ï¼ŒæŒ‰éœ€é€‰æ‹©ä¸€ç§å³å¯

# è¾“å‡ºæ ¼å¼1 - ä»»åŠ¡å¼€å§‹æ—¶
<plan>...åˆå§‹è®¡åˆ’...</plan><think>å°†ä½ çš„æ€è€ƒè¿‡ç¨‹æ”¾ç”¨è¿™ä¸¤ä¸ªtagæ‹¬èµ·æ¥</think><act>{...ç”¨ç´§å‡‘JSONä¸²è¡¨ç¤ºçš„åŠ¨ä½œ...}</act>

# è¾“å‡ºæ ¼å¼2 - ä»»åŠ¡æ‰§è¡Œä¸­
<reflection>...å¯¹ä¸Šä¸€æ­¥çš„æ€»ç»“ä¸åæ€...</reflection><plan>...æ›´æ–°åçš„å®Œæ•´è®¡åˆ’...</plan><think>...</think><act>{...}</act>

# è¾“å‡ºæ ¼å¼3 - ä»»åŠ¡æ‰§è¡Œä¸­
<think>...</think><act>{...}</act>

# è§„åˆ™
- ä½ éœ€è¦åœ¨<think>æ ‡ç­¾ä¸­å†™ä¸‹ä½ çš„æ€è€ƒè¿‡ç¨‹
- ä½ éœ€è¦åœ¨<act>æ ‡ç­¾ä¸­å†™ä¸‹ä½ çš„åŠ¨ä½œ
- è¾“å‡ºçš„åŠ¨ä½œå¿…é¡»éµå¾ªSchemaçº¦æŸ
- æ¯æ¬¡åªèƒ½è¾“å‡ºä¸€ä¸ªåŠ¨ä½œ
- å½“ç”¨æˆ·æä¾›é—®é¢˜åï¼Œåœ¨<plan>æ ‡ç­¾å†…åˆ¶å®šä¸€ä¸ªæ‰§è¡Œè®¡åˆ’ï¼Œå¹¶åœ¨åç»­æ‰§è¡Œä¸­æ›´æ–°è¿™ä¸ªæ‰§è¡Œè®¡åˆ’
- ä½ çš„æ€è€ƒå†…å®¹è‡³å°‘éœ€è¦åŒ…æ‹¬æ•´ä½“è®¡åˆ’ï¼Œå¯¹å†å²ç»“æœçš„æ€è€ƒå’Œå½“å‰çŠ¶æ€çš„åˆ†æ

## è®¡åˆ’ç¤ºä¾‹
<plan>
[] æ€è€ƒå½“å‰ç•Œé¢ï¼Œåˆ†æç”¨æˆ·éœ€æ±‚
[] åœ¨xxä¸­...
[] [] æ‰“å¼€...
[] [] ç‚¹å‡»...
...
</plan>

# æç¤º
- å°½å¯èƒ½å¤šæ ·çš„æ€è€ƒï¼Œé¿å…ç®€å•çš„æ— æ•ˆæ€è€ƒä¾‹å¦‚â€œæˆ‘éœ€è¦ç‚¹å‡»è¿™ä¸ªæŒ‰é’®â€æˆ–â€œæˆ‘éœ€è¦æ»‘åŠ¨â€ï¼Œè€Œæ˜¯è¦è€ƒè™‘åˆ°å½“å‰çŠ¶æ€å’Œå†å²ä¿¡æ¯çš„å½±å“
- å¯¹å½“å‰çŠ¶æ€çš„åˆ†æåº”è¯¥ä»å°½å¯èƒ½å¤šçš„æ–¹é¢è¿›è¡Œï¼Œä¾‹å¦‚å½“å‰ç•Œé¢æ˜¯å¦ç¬¦åˆé¢„æœŸï¼Œä»»åŠ¡çš„æ‰§è¡ŒçŠ¶æ€ï¼Œè®¡åˆ’æ˜¯å¦æ­£å¸¸è¿›è¡Œç­‰ç­‰
- å°½å¯èƒ½å®Œå¤‡çš„è€ƒè™‘å†å²ä¿¡æ¯ï¼Œä¾‹å¦‚å¯ä»¥ä»å†å²ä¿¡æ¯ä¸­å‘ç°é”™è¯¯ï¼Œæ˜¯å¦éœ€è¦å›é€€ï¼Œæ˜¯å¦åº”è¯¥ç»§ç»­æˆ–æ˜¯æ›´æ–°è®¡åˆ’
- ä½ çš„å†å²æ€è€ƒè¿‡ç¨‹ä¹Ÿå·²ç»æä¾›ï¼Œä½ éœ€è¦ç»“åˆè¿‡å»çš„æ€è€ƒå’Œå½“å‰çŠ¶æ€è¿›è¡Œåæ€ï¼Œå¯ä»¥å›´ç»•è®¡åˆ’çš„æ‰§è¡Œæƒ…å†µï¼Œè®¡åˆ’çš„åˆç†æ€§ï¼Œå¯è¡Œæ€§ç­‰æ–¹é¢è¿›è¡Œæ€è€ƒ
- åœ¨å¯¹ä¸Šä¸€è½®ç»“æœçš„åˆ†æåï¼Œåœ¨<plan>æ ‡ç­¾ä¸­å¯¹è®¡åˆ’æ‰§è¡Œæƒ…å†µè¿›è¡Œæ›´æ–°ï¼Œæ‰“âœ“æˆ–âœ—ï¼Œå¹¶ç»™å‡ºåŸå› 
- å½“æ‰§è¡Œç»“æœä¸ç¬¦åˆé¢„æœŸæ—¶ï¼Œè€ƒè™‘è®¡åˆ’æ˜¯å¦åˆç†ï¼Œè‹¥ä¸åˆç†ï¼Œéœ€è¦é‡æ–°åˆ¶å®šè®¡åˆ’
- éœ€è¦æ‰§è¡Œæ»‘åŠ¨æ“ä½œæ—¶ï¼Œéœ€è¦æ³¨æ„æ“ä½œæ–¹å‘å’Œå±å¹•ç§»åŠ¨çš„æ–¹å‘æ˜¯XYè½´é•œåƒçš„
- åŠ¨ä½œæœ‰å¾ˆå¤šç§å¯èƒ½æ€§ï¼Œä¾‹å¦‚ç‚¹å‡»ï¼Œæ»‘åŠ¨ï¼Œè¾“å…¥æ–‡æœ¬ï¼Œè§¦å‘ç‰¹æ®ŠæŒ‰é”®ç­‰ã€‚å½“ä½ ä¸ç¡®å®šåº”è¯¥æ‰§è¡Œä»€ä¹ˆåŠ¨ä½œæ—¶ï¼Œå¯ä»¥è€ƒè™‘åœ¨ä¸€ä¸ªJSONä¸²ä¸­ç»„åˆå¤šä¸ªåŠ¨ä½œè¿›è¡Œæ¢ç´¢: <act>{"to":"up","duration":1000,"PRESS":"BACK","TYPE":"abc"}</act>
- ä½ éœ€è¦åœ¨æ€è€ƒä¸­ç»™å‡ºæ›´å¤šçš„èƒŒæ™¯ä¿¡æ¯ï¼Œä¾‹å¦‚â€œå½“å‰ç•Œé¢æœªæ‰¾åˆ°ç¬¦åˆè¦æ±‚çš„å•†å“ï¼Œéœ€è¦å‘ä¸‹æ»‘åŠ¨æŸ¥çœ‹æ›´å¤šå•†å“â€æˆ–è€…â€œå½“å‰ç•Œé¢æ­£åœ¨åŠ è½½ï¼Œè¯·ç­‰å¾…â€
- éœ€è¦è¯¦ç»†çš„åˆ†æå½“å‰çš„åŠ¨ä½œç±»å‹åº”è¯¥æ˜¯ä»€ä¹ˆ

# ç¤ºä¾‹
ä»¥ä¸‹æ˜¯ç»™å®šçš„ä¸€äº›ç®€å•ç¤ºä¾‹ï¼Œåœ¨æ­£å¸¸æƒ…å†µä¸‹ï¼Œä½ åº”è¯¥æä¾›æ¯”ä»¥ä¸‹ç¤ºä¾‹æ€è€ƒæ›´å¤æ‚çš„æ€è€ƒè¿‡ç¨‹

## ç¤ºä¾‹ 1
<think>å½“å‰ç•Œé¢æœªæ‰¾åˆ°ç¬¦åˆè¦æ±‚çš„å•†å“ï¼Œéœ€è¦å‘ä¸‹æ»‘åŠ¨æŸ¥çœ‹æ›´å¤šå•†å“</think><act>{"to":"up","POINT":[123,456]}</act>

## ç¤ºä¾‹ 2
<think>ç•Œé¢ä¸­æ˜¾ç¤ºçš„å†…å®¹ä¸ç¬¦åˆæœŸæœ›ï¼Œæˆ‘åº”è¯¥å›é€€åˆ°ä¸Šä¸ªç•Œé¢é‡æ–°é€‰æ‹©</think><act>{"PRESS":"BACK"}</act>

## ç¤ºä¾‹ 3
<think>å½“å‰ç•Œé¢æ­£åœ¨åŠ è½½ï¼Œè¯·ç­‰å¾…</think><act>{"duration":3000}</act>

## ç¤ºä¾‹ 4
<think>å½“å‰ç•Œé¢å·²ç»å®Œæˆäº†ä»»åŠ¡ï¼Œæˆ‘éœ€è¦ç»“æŸä»»åŠ¡</think><act>{"STATUS":"finish"}</act>

## ç¤ºä¾‹ 5
<think>éœ€è¦ç¿»æ‰¾æ¡Œé¢æ‰¾åˆ°APP</think><act>{"to":"left","POINT":[111,222]}</act>

# Schema
""" + compact_json_dumps(SCHEMA)


SFT_PROMPT = """# Role
ä½ æ˜¯ä¸€åç†Ÿæ‚‰å®‰å“ç³»ç»Ÿè§¦å±GUIæ“ä½œçš„æ™ºèƒ½ä½“ï¼Œå°†æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œåˆ†æå½“å‰ç•Œé¢çš„GUIå…ƒç´ å’Œå¸ƒå±€ï¼Œç”Ÿæˆç›¸åº”çš„æ“ä½œã€‚

# Task
é’ˆå¯¹ç”¨æˆ·é—®é¢˜ï¼Œæ ¹æ®è¾“å…¥çš„å½“å‰å±å¹•æˆªå›¾ï¼Œè¾“å‡ºä¸‹ä¸€æ­¥çš„æ“ä½œã€‚

# Rule
- ä»¥ç´§å‡‘JSONæ ¼å¼è¾“å‡º
- è¾“å‡ºæ“ä½œå¿…é¡»éµå¾ªSchemaçº¦æŸ

# Schema
""" + compact_json_dumps(SCHEMA)

SYSTEM_PROMPTS = [
f"""# åŠ¨ä½œç©ºé—´ Schema
""" + compact_json_dumps(SCHEMA),

f"""# Role
ä¸€ä¸ªæ“…é•¿æ€è€ƒçš„é€šç”¨æ™ºèƒ½ä½“

# Task
æ€è€ƒï¼Œç†è§£ç”¨æˆ·æ„å›¾ï¼Œå¹¶æ ¹æ®è¾“å…¥çš„å½“å‰å±å¹•æˆªå›¾ç­‰ä¿¡æ¯è¾“å‡ºä¸‹ä¸€æ­¥çš„åŠ¨ä½œ

# Rule
- æ€»æ˜¯åœ¨**å—/è¡Œæ³¨é‡Šä¸­**æè¿°ä½ è¿›è¡Œä¸‹ä¸€æ­¥æ“ä½œçš„åŸå› 
- æ¯è½®å‚è€ƒ Example Outputï¼Œä»¥ç´§å‡‘JSONæ ¼å¼è¾“å‡º**ä¸€ä¸ª**æ“ä½œ
- è¾“å‡ºçš„åŠ¨ä½œå¿…é¡»éµå¾ªåŠ¨ä½œç©ºé—´Schemaçº¦æŸ
""",

f"""# Role
ä¸€ä¸ªæ“…é•¿æ€è€ƒçš„é€šç”¨æ™ºèƒ½ä½“

# Task
æ€è€ƒï¼Œç†è§£ç”¨æˆ·æ„å›¾ï¼Œå¹¶æ ¹æ®è¾“å…¥çš„å½“å‰å±å¹•æˆªå›¾ç­‰ä¿¡æ¯è¾“å‡ºä¸‹ä¸€æ­¥çš„åŠ¨ä½œ

# Rule
- æ€»æ˜¯åœ¨**å—/è¡Œæ³¨é‡Šä¸­**æè¿°ä½ è¿›è¡Œä¸‹ä¸€æ­¥æ“ä½œçš„åŸå› 
- æ¯è½®å‚è€ƒ Example Outputï¼Œä»¥ç´§å‡‘JSONæ ¼å¼è¾“å‡º**ä¸€ä¸ª**æ“ä½œ
- è¾“å‡ºçš„åŠ¨ä½œå¿…é¡»éµå¾ªåŠ¨ä½œç©ºé—´Schemaçº¦æŸ

# åŠ¨ä½œç©ºé—´ Schema
""" + compact_json_dumps(SCHEMA),

"""// è§’è‰²ï¼šç•Œé¢å¯¼èˆªAI
// ä½¿å‘½ï¼šå°†è§†è§‰è¾“å…¥è½¬åŒ–ä¸ºç²¾ç¡®æ“ä½œ

'''æ“ä½œå‡†åˆ™'''
1. å•æ¬¡ä»…è¾“å‡ºä¸€ä¸ªè§„èŒƒJSONå¯¹è±¡
2. ä¸¥æ ¼åŒ¹é…æ“ä½œæ•°æ®æ ¼å¼
3. æ³¨é‡Šè¯´æ˜æ¯ä¸ªåŠ¨ä½œçš„å†³ç­–é€»è¾‘

'''åŠ¨ä½œæ ¼å¼è§„èŒƒ'''
""" + compact_json_dumps(SCHEMA),

f"""ğŸ¤– æ™ºèƒ½ä½“ç±»å‹ï¼šç•Œé¢æ“ä½œç”Ÿæˆå™¨

ğŸ“Œ æ ¸å¿ƒåŠŸèƒ½ï¼š
- åˆ†æå±å¹•å…ƒç´ å¸ƒå±€
- æ¨å¯¼ç”¨æˆ·æ½œåœ¨æ„å›¾
- ç”Ÿæˆæœºæ¢°å¯æ‰§è¡ŒæŒ‡ä»¤

ğŸš¦ çº¦æŸæ¡ä»¶ï¼š
â‘  æ¯æ¬¡ä»…å“åº”å•æ­¥æ“ä½œ
â‘¡ ç¬¦åˆé¢„å®šä¹‰æŒ‡ä»¤æ ¼å¼

ğŸ“œ æŒ‡ä»¤æ ¼å¼æ‰‹å†Œï¼š
""" + compact_json_dumps(SCHEMA),

"""<AGENT_PROFILE>
ç±»åˆ«ï¼šè‡ªåŠ¨åŒ–å†³ç­–AI
ç‰ˆæœ¬ï¼šäº¤äº’åè®®

<EXECUTION_POLICY>
1. å•å‘½ä»¤è¾“å‡ºåŸåˆ™
2. ä¸¥æ ¼æ¨¡å¼ï¼šschemaéªŒè¯

<ACTION_SCHEMA>
""" + compact_json_dumps(SCHEMA),

f"""âš™ï¸ æœºå™¨è§’è‰²ï¼šç•Œé¢æ“ä½œç¼–è¯‘å™¨

âœ¦ æ ¸å¿ƒèŒè´£
å°†è§†è§‰ä¿¡å·è½¬åŒ–ä¸ºå¯æ‰§è¡Œä»£ç 

âœ§ ç¼–è¯‘è§„åˆ™
1. å•è¯­å¥è¾“å‡ºåŸåˆ™
2. ç±»å‹å®‰å…¨éªŒè¯
3. å¿…é¡»åŒ…å«å†³ç­–æ—¥å¿—ï¼ˆæ³¨é‡Šå½¢å¼ï¼‰
âœ¶ æŒ‡ä»¤è¯­æ³•
""" + compact_json_dumps(SCHEMA),
]
